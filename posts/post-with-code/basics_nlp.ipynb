{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5299bb77",
   "metadata": {},
   "source": [
    "# Basics of Natural Language Processing in Python\n",
    "Natural langauge processing enables computer to human languages. It combines linguistic with statistical modeling. \n",
    "In this post, we will become familiar with basics of nlp with Python. We will use NLTK library for the tutorial.\n",
    "\n",
    "## Installation\n",
    "First we need to install nltk library. The following command can be used to do that.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a02da0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d7bf4b",
   "metadata": {},
   "source": [
    "## Basic concepts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f238e6c",
   "metadata": {},
   "source": [
    "Now, we will get familiar with basic concepts of nlp. Every nlp application usually takes a large amount of text data to train. This text data, however, is not understandable directly by the computer. To allow a computer to understand text data, the data needs to be converted into numbers. This process is broken down into the following steps\n",
    "\n",
    "* Tokenization\n",
    "* Parts of Speech Tagging\n",
    "* 1-hot Encoding\n",
    "* Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049729b6",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "Let's start with tokenization, the first step in the process. Tokenization step simply breaks down a text data into smaller units, also known as tokens. These tokens could be words, punctuation marks, numbers, etc.\n",
    "\n",
    "\n",
    "Let's take an example to understand this step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34dd9797",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/pankaj/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d76b2586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences:\n",
      " ['This post offers basics of natural langauge processing (NLP) in Python.', 'NLP enables computer to human languages.', 'It combines linguistic with statistical modeling.']\n",
      "Words:\n",
      " [['This', 'post', 'offers', 'basics', 'of', 'natural', 'langauge', 'processing', '(', 'NLP', ')', 'in', 'Python', '.'], ['NLP', 'enables', 'computer', 'to', 'human', 'languages', '.'], ['It', 'combines', 'linguistic', 'with', 'statistical', 'modeling', '.']]\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, sent_tokenize\n",
    "\n",
    "text = \"\"\"This post offers basics of natural langauge processing (NLP) in Python. \n",
    "    NLP enables computer to human languages. It combines linguistic with statistical modeling.\n",
    "    \"\"\"\n",
    "\n",
    "# Breaking the text data into sentences\n",
    "sentences = sent_tokenize(text)\n",
    "print('Sentences:\\n',sentences)\n",
    "\n",
    "# Breaking each sentece into words\n",
    "words = [word_tokenize(sentence) for sentence in sentences]\n",
    "print('Words:\\n',words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e3b5f4",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "    \n",
    "    If you get an error while running the above code then run the following statement.\n",
    "    \n",
    "    ```\n",
    "    import nltk\n",
    "    nltk.download('punkt')\n",
    "    ```\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5aea85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
