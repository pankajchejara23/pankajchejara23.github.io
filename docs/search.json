[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Pankaj Chejara is a junior researcher cum web developer at the Center of Education Technology at Tallinn University, Estonia. His work is primarily focused on building AI tools to support teachers in the classroom with group work monitoring. He enjoys diving into data to extract insights and is always ready to learn new things to solve the problem at hand. When not working on data analytics projects, Pankaj enjoys spending time with his son and watching animated movies."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About Me",
    "section": "Education",
    "text": "Education\nPhD in Learning Analytics (Thesis Submitted) | Sept 2018 - Nov 2023 Tallinn University, Tallinn | Tallinn, Estonia\nMaster in Computer Engg. (MTech) | Aug 2010 - June 2012  Malviya National Institute of Technology | Jaipur, India\nMaster in Computer Applications (MCA) | Aug 2007 - May 2010  Malviya National Institute of Technology | Jaipur, India\nBachelor in Science (Mathematics) | Aug 2004 - May 2007  University of Rajasthan | Jaipur, India"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About Me",
    "section": "Experience",
    "text": "Experience\nWeb Developer | Tallinn University, Estonia | Sep 2019 - present Assistant Professor | Sharda University, India | Sep 2012 - 2016"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Pankaj Chejara",
    "section": "",
    "text": "Introduction to Python Dash Framework\n\n\n\n\n\n\n\npython\n\n\nvisualization\n\n\nweb-app\n\n\n\n\n\n\n\n\n\n\n\nJun 3, 2023\n\n\nPankaj Chejara\n\n\n\n\n\n\n  \n\n\n\n\nFacial feature extraction using OpenFace\n\n\n\n\n\n\n\npython\n\n\nopenface\n\n\nfacial features\n\n\n\n\n\n\n\n\n\n\n\nMar 28, 2020\n\n\nPankaj Chejara\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/facial-features.html",
    "href": "posts/post-with-code/facial-features.html",
    "title": "Facial feature extraction using OpenFace",
    "section": "",
    "text": "In this post, I will discuss the work I have been doing recently. I needed to extract facial features from the recorded video and for this task, I decided to use OpenFace, an open-source face recognition library. In this post, I am sharing the installation process and tutorial on detecting facial landmarks.\n\n\nInstallation\nI tried to install OpenFace on Mac OS but couldn’t succeed. There were a lot of errors and compatibility issues that I couldn’t get through. Therefore, I decided to install it on Ubuntu. For that, I installed a Virtual box on Mac and installed Ubuntu 18.04.\nTo install OpenFace, I followed the steps given here\nsudo apt-get update\nsudo apt-get install build-essential\nsudo apt-get install g++-8\n\nsudo apt-get install cmake\n\nsudo apt-get install git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev\n\nsudo apt-get install python-dev python-numpy libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libdc1394-22-dev\n\nwget https://github.com/opencv/opencv/archive/4.1.0.zip\n\nsudo unzip 4.1.0.zip\ncd opencv-4.1.0\nmkdir build\ncd build\n\ncmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D BUILD_TIFF=ON -D WITH_TBB=ON ..\nmake -j2\nsudo make install\n\nwget http://dlib.net/files/dlib-19.13.tar.bz2\ntar xf dlib-19.13.tar.bz2\ncd dlib-19.13\nmkdir build\ncd build\ncmake ..\ncmake --build . --config Release\nsudo make install\nsudo ldconfig\ncd ../..\n\nsudo apt-get install libboost-all-dev\n\ngit clone https://github.com/TadasBaltrusaitis/OpenFace.git\n\ncd OpenFace\nmkdir build\ncd build\n\ncmake -D CMAKE_CXX_COMPILER=g++-8 -D CMAKE_C_COMPILER=gcc-8 -D CMAKE_BUILD_TYPE=RELEASE ..\nmake\nAt this point, we have installed OpenFace. Now we need to download models. You can either download it manually or use a script provided in the OpenFace library.\nManual download links.\n\nscale 0.25\nscale 0.35\nscale 0.50\nscale 1.00\n\nI ran the following command to ran the script to download the model.\ncd ..\nsh ./download_models.sh\nThe script will download models in the directory OpenFace/lib/local/LandmarkDetector/model/patch_experts.\nAfter completing this process, I ran the demo program by running the following command.\n./bin/FaceLandmarkVid -f \"\"../samples/changeLighting.wmv\"\" -f \"\"../samples/2015-10-15-15-14.avi\nI got an error CEN patch expert not found. The command was searching the models in the OpenFace/build/bin/model/patch_experts. So I copied the files (cen_patches_0.25_of.dat,cen_patches_0.35_of.dat,cen_patches_0.50_of.dat,cen_patches_1.00_of.dat) in `OpenFace/build/bin/model/patch_experts directory.\n\n\nRunning Demo\nIf you have a video with a single face, you can use FaceLandmarkVid or in case of multiple faces, you can use FaceLandmarkVidMulti\nFollowing is the demonstration of OpenFace on a video clip with single face.\n::: {.callout-note}\nNote that there are five types of callouts, including:\n`note`, `warning`, `important`, `tip`, and `caution`.\n:::\nFaceLandmarkVid -f file_name\n\n\n\nIMAGE ALT TEXT HERE"
  },
  {
    "objectID": "posts/post-with-code/dash.html",
    "href": "posts/post-with-code/dash.html",
    "title": "Introduction to Python Dash Framework",
    "section": "",
    "text": "Dashboards play a crucial role in conveying useful and actionable information from collected data regardless of context. As with economically feasible sensors, improved computation, storage facility, and IoT framework, it has become easier to collect an enormous amount of data from a variety of contexts (e.g. military, health-care, education). However, finding insights from collected data remains a challenge. This post offers an introduction to Python Dash a framework that is a great option for dashboard development. I personally really like this framework. It allows me to process my data along with its visualization through a web-based application."
  },
  {
    "objectID": "posts/post-with-code/dash.html#dash-framework",
    "href": "posts/post-with-code/dash.html#dash-framework",
    "title": "Introduction to Python Dash Framework",
    "section": "Dash Framework",
    "text": "Dash Framework\ndash uses plotly graphics library for plotting graphs. In addition to their graphic feature, these graphs also have a lot of good features (e.g. automatic scaling of axis for timestamp data, etc). Please refer dash documentation for details.\n\nInstallation\npip install dash-html-components==0.14.0  # HTML components\npip install dash-core-components==0.44.0  # dash core components\npip install dash-table==3.6.0  # Interactive DataTable component (new!)\n\n\nFirst dash application\nNow, we are going to develop our first dash application. For this application, we are going to plot the following data (some records are taken from &lt;a href=““https://github.com/ywchiu/riii/blob/master/data/house-prices.csv”“&gt;here. This data has two attributes (House price and area).\nA dash application can have number of components (e.g. div block, table, headings, graph). In our application, we are going to use two components - heading and a graph. Let’s begin developing it. First of all, we need to import the required packages\nimport dash_core_components as dcc\nimport dash_html_components as html\nThe first package is used to create an object of dash application. Second package dash_core_components provides graph components and the third package allows us to include html components (heading, input box) in our application.\nNext, we need to create a dash application.\napp = dash.Dash(__name__)\nname is a special variable in python which contains name of current module. For instance, when you run your python program using command prompt then it contains main.\nNow, we will create components to embed in our application. Just to have a clear idea, we want to create following structured with our application.\n\n\n First Dash Application \n\n graph here.. \n\n\nFor components, we will use dash_html_components and for graph, we will use dash_core_components.\nlist_of_data = [{\n    'y':[114300,114200,114800,94700,119800,114600],\n    'x':[1790,2030,1740,1980,2130,1780],\n    'type':'bar'\n}]\n\nbody = html.Div([\n    html.H2(\"\"First Dash Application\"\"),\n    dcc.Graph(id='first',\n        figure={'data':list_of_data})\n])\nIn the above code, we created the body of our application which is a div block. In this block, we created one H2 heading component and one Graph component. Graph has a attribute figure where we have specified the data to be plotted. The data (list_of_data) is actually a list of dictionaries (It might seems a bit confusing but you will be good after writing some codes). One important thing-&gt; we used ‘type’:‘bar’ which specify that we want to plot Bar chart.\nNext, we will set the layout of the application.\napp.layout = html.Div([body])\nFinally, we will start the server\nif __name__ == \"\"__main__\"\":\n    app.run_server(debug=True)\nYou can download this script from here.\nNow, we will execute our application. The execution of our application will start a server on the port 8050\n\n\n\nRunning the server\n\n\nIn order to see the output of the program, open your browser and type http://127.0.0.1:8050 in the address bar. It will show you the following screen\n\n\n\np6.3.png\n\n\nCheck for more components: dash_core_components, dash_html_components.\n\n\nAdding CSS style to the app\nThe next step towards generating a beautiful dashboard is to add a styling feature. We can use css (&lt;a href=““https://www.w3schools.com/css/”“&gt;what is css?) stylesheet in our application. It can be specified at the time of creating an application.\napp = dash.app = dash.Dash(__name__,external_stylesheets=style)\nWith the above method, you can only add css which are available online. In case if you want to add your local css file, follow the given steps\n\nCreate a folder with name asset in the same directory where your dash script is stored.\nCopy your stylesheet in the asset folder.\nAdd the path in your program\n\ndash.Dash(__name__,external_stylesheets=[\"\"\\asset\\css-file-name\"\"])\n\n\nInstalling Bootstrap component for dash\ndash also supports Bootstrap (&lt;a href=““https://getbootstrap.com/docs/4.3/getting-started/introduction/”“&gt;Introduction) which is a widely used css library. It can be added in your dash application using dash-bootstrap-component package (&lt;a href=”“https://dash-bootstrap-components.opensource.faculty.ai/l/components”“&gt;complete documentation). This package allows an easy integration of Bootstrap in the dash application.\nYou can install it using the following command.\npip install dash-bootstrap-components\nNow, let’s use it to add a CSS to our first example. We are going to create the following layout for our application. We will utilize Bootstrap’s grid system for structuring our components.\n\n\n\nboot.png\n\n\nFirst, we need to import dash_bootstrap_components in our previous example.\nNext, we will add bootstrap css to your program and then we will create our layout.\nimport dash-bootstrap-components as dbc\napp = dash.Dash(__name__,external_stylesheets=[dbc.themes.BOOTSTRAP])\n\n# column1 content\ncolumn_1 = [\n    html.H2(\"\"House Prices\"\"),\n    html.P(\"\"This is a demo application which shows house prices with house area.\"\"\n    ),\n    dbc.Button(\"\"Details\"\", color=\"\"secondary\"\"),\n]\n\n# column content\ncolumn_2 = [\n    html.H2(\"\"Graph\"\"),\n    dcc.Graph(id='first',\n        figure={'data':list_of_data}),\n]\n\n# Creating layout\nbody = dbc.Container(\n    [   html.H1('With Bootstrap'),\n        html.Hr(),\n        dbc.Row(\n            [\n                dbc.Col(column_1,md=4),\n                dbc.Col(column_2,md=8),\n            ]\n        )\n    ]\n)\n\n# Adding CSS\n# dash-bootstrap-components has CDN for bootstrap css in dbc.themes.BOOTSTRAP\napp = dash.Dash(__name__,external_stylesheets=[dbc.themes.BOOTSTRAP])\nYou can chek the above source code here."
  },
  {
    "objectID": "Projects.html",
    "href": "Projects.html",
    "title": "Projects",
    "section": "",
    "text": "The following projects focus on utilizing the power of analytics to support teaching and learning experience.\n\n\nDemo | Publication | Source code\nPython, Dash\n\nA Raspberry Pi-based prototype to capture audio data from face-to-face group activity\nAnalyzed the direction of arrival of captured audio to compute speaking time and turn-taking using python\nDeveloped an interactive dashboard for data visualization\n\n\n\n\n\n:trophy: Best Demo Award at Learning Analytics and Knowledge (LAK2023) conference, Texas, USA (Core A rank)\nDemo | Publication | Source code\nPython , jQuery, MySQL, Etherpad, plotly, Google Speech-to-Text\n\nPython Django app to collect multimodal learning data from group activities in classrooms\nVoice activity detection to compute speaking time of individual in group activities in real-time\nGoogle Speech-To-Text integration to process audio in real-time\nA real-time dashboard visualizing group’s writing behavior, speaking participation, and speech content (in the form of word cloud)\n\n\n\n\n\n\nPublication | Source code\nPython , Scikit-learn, Matplotlib\n\nAnalyzed audio and log data gathered from Estonian classrooms during group activities\nExplored use of different temporal window size (30s, 60s, 90s, 120s, 180s, 240s) to process features such as speaking time, turn-taking\nDeveloped machine learning models to predict collaboration quality using audio and log data features processed with different window sizes\n\n\n\n\n\n\nPublication\nPython , Scikit-learn, Matplotlib\n\nAnalyzed audio, video and log data to develop machine learning models to predict collaboration quality in classroom settings during group activity\nUsed Random Forest algorithm to develop model and evaluated its generalizability with a different dataset collected from a different Estonian school"
  },
  {
    "objectID": "Projects.html#edtech-projects",
    "href": "Projects.html#edtech-projects",
    "title": "Projects",
    "section": "",
    "text": "The following projects focus on utilizing the power of analytics to support teaching and learning experience.\n\n\nDemo | Publication | Source code\nPython, Dash\n\nA Raspberry Pi-based prototype to capture audio data from face-to-face group activity\nAnalyzed the direction of arrival of captured audio to compute speaking time and turn-taking using python\nDeveloped an interactive dashboard for data visualization\n\n\n\n\n\n:trophy: Best Demo Award at Learning Analytics and Knowledge (LAK2023) conference, Texas, USA (Core A rank)\nDemo | Publication | Source code\nPython , jQuery, MySQL, Etherpad, plotly, Google Speech-to-Text\n\nPython Django app to collect multimodal learning data from group activities in classrooms\nVoice activity detection to compute speaking time of individual in group activities in real-time\nGoogle Speech-To-Text integration to process audio in real-time\nA real-time dashboard visualizing group’s writing behavior, speaking participation, and speech content (in the form of word cloud)\n\n\n\n\n\n\nPublication | Source code\nPython , Scikit-learn, Matplotlib\n\nAnalyzed audio and log data gathered from Estonian classrooms during group activities\nExplored use of different temporal window size (30s, 60s, 90s, 120s, 180s, 240s) to process features such as speaking time, turn-taking\nDeveloped machine learning models to predict collaboration quality using audio and log data features processed with different window sizes\n\n\n\n\n\n\nPublication\nPython , Scikit-learn, Matplotlib\n\nAnalyzed audio, video and log data to develop machine learning models to predict collaboration quality in classroom settings during group activity\nUsed Random Forest algorithm to develop model and evaluated its generalizability with a different dataset collected from a different Estonian school"
  }
]