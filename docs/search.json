[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Pankaj Chejara is a junior researcher cum web developer at the Center of Education Technology at Tallinn University, Estonia. His work is primarily focused on building AI tools to support teachers in the classroom with group work monitoring. He enjoys diving into data to extract insights and is always ready to learn new things to solve the problem at hand. When not working on data analytics projects, Pankaj enjoys spending time with his son and watching animated movies."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About Me",
    "section": "Education",
    "text": "Education\nPhD in Learning Analytics (Thesis Submitted) | Sept 2018 - Nov 2023 Tallinn University, Tallinn | Tallinn, Estonia\nMaster in Computer Engg. (MTech) | Aug 2010 - June 2012  Malviya National Institute of Technology | Jaipur, India\nMaster in Computer Applications (MCA) | Aug 2007 - May 2010  Malviya National Institute of Technology | Jaipur, India\nBachelor in Science (Mathematics) | Aug 2004 - May 2007  University of Rajasthan | Jaipur, India"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About Me",
    "section": "Experience",
    "text": "Experience\nWeb Developer | Tallinn University, Estonia | Sep 2019 - present Assistant Professor | Sharda University, India | Sep 2012 - 2016"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Pankaj Chejara",
    "section": "",
    "text": "Introduction to Python Dash Framework\n\n\n\n\n\n\n\npython\n\n\nvisualization\n\n\nweb-app\n\n\n\n\n\n\n\n\n\n\n\nJun 3, 2023\n\n\nPankaj Chejara\n\n\n\n\n\n\n  \n\n\n\n\nUnderstanding Principal Component Analysis under the hood\n\n\n\n\n\n\n\nmachine learning\n\n\nPCA\n\n\ndimensionality reduction\n\n\npython\n\n\nscikit-learn\n\n\n\n\n\n\n\n\n\n\n\nApr 22, 2020\n\n\nPankaj Chejara\n\n\n\n\n\n\n  \n\n\n\n\nFacial feature extraction using OpenFace\n\n\n\n\n\n\n\npython\n\n\nopenface\n\n\nfacial features\n\n\n\n\n\n\n\n\n\n\n\nMar 28, 2020\n\n\nPankaj Chejara\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/dash.html",
    "href": "posts/post-with-code/dash.html",
    "title": "Introduction to Python Dash Framework",
    "section": "",
    "text": "Dashboards play a crucial role in conveying useful and actionable information from collected data regardless of context. As with economically feasible sensors, improved computation, storage facility, and IoT framework, it has become easier to collect an enormous amount of data from a variety of contexts (e.g. military, health-care, education). However, finding insights from collected data remains a challenge. This post offers an introduction to Python Dash a framework that is a great option for dashboard development. I personally really like this framework. It allows me to process my data along with its visualization through a web-based application."
  },
  {
    "objectID": "posts/post-with-code/dash.html#dash-framework",
    "href": "posts/post-with-code/dash.html#dash-framework",
    "title": "Introduction to Python Dash Framework",
    "section": "Dash Framework",
    "text": "Dash Framework\ndash uses plotly graphics library for plotting graphs. In addition to their graphic feature, these graphs also have a lot of good features (e.g. automatic scaling of axis for timestamp data, etc). Please refer dash documentation for details.\n\nInstallation\npip install dash-html-components==0.14.0  # HTML components\npip install dash-core-components==0.44.0  # dash core components\npip install dash-table==3.6.0  # Interactive DataTable component (new!)\n\n\nFirst dash application\nNow, we are going to develop our first dash application. For this application, we are going to plot the following data (some records are taken from here. This data has two attributes (House price and area).\nA dash application can have number of components (e.g. div block, table, headings, graph). In our application, we are going to use two components - heading and a graph. Let’s begin developing it. First of all, we need to import the required packages\nimport dash_core_components as dcc\nimport dash_html_components as html\nThe first package is used to create an object of dash application. Second package dash_core_components provides graph components and the third package allows us to include html components (heading, input box) in our application.\nNext, we need to create a dash application.\napp = dash.Dash(__name__)\nname is a special variable in python which contains name of current module. For instance, when you run your python program using command prompt then it contains main.\nNow, we will create components to embed in our application. Just to have a clear idea, we want to create following structured with our application.\n\n\n First Dash Application \n\n graph here.. \n\n\nFor components, we will use dash_html_components and for graph, we will use dash_core_components.\nlist_of_data = [{\n    'y':[114300,114200,114800,94700,119800,114600],\n    'x':[1790,2030,1740,1980,2130,1780],\n    'type':'bar'\n}]\n\nbody = html.Div([\n    html.H2(\"\"First Dash Application\"\"),\n    dcc.Graph(id='first',\n        figure={'data':list_of_data})\n])\nIn the above code, we created the body of our application which is a div block. In this block, we created one H2 heading component and one Graph component. Graph has a attribute figure where we have specified the data to be plotted. The data (list_of_data) is actually a list of dictionaries (It might seems a bit confusing but you will be good after writing some codes). One important thing-&gt; we used ‘type’:‘bar’ which specify that we want to plot Bar chart.\nNext, we will set the layout of the application.\napp.layout = html.Div([body])\nFinally, we will start the server\nif __name__ == \"\"__main__\"\":\n    app.run_server(debug=True)\nYou can download this script from here.\nNow, we will execute our application. The execution of our application will start a server on the port 8050\n\n\n\nRunning the server\n\n\nIn order to see the output of the program, open your browser and type http://127.0.0.1:8050 in the address bar. It will show you the following screen\n\n\n\np6.3.png\n\n\nCheck for more components: dash_core_components, dash_html_components.\n\n\nAdding CSS style to the app\nThe next step towards generating a beautiful dashboard is to add a styling feature. We can use css stylesheet in our application. It can be specified at the time of creating an application.\napp = dash.app = dash.Dash(__name__,external_stylesheets=style)\nWith the above method, you can only add css which are available online. In case if you want to add your local css file, follow the given steps\n\nCreate a folder with name asset in the same directory where your dash script is stored.\nCopy your stylesheet in the asset folder.\nAdd the path in your program\n\ndash.Dash(__name__,external_stylesheets=[\"\"\\asset\\css-file-name\"\"])\n\n\nInstalling Bootstrap component for dash\ndash also supports Bootstrap which is a widely used css library. It can be added in your dash application using dash-bootstrap-component package (complete documentation). This package allows an easy integration of Bootstrap in the dash application.\nYou can install it using the following command.\npip install dash-bootstrap-components\nNow, let’s use it to add a CSS to our first example. We are going to create the following layout for our application. We will utilize Bootstrap’s grid system for structuring our components.\n\n\n\nboot.png\n\n\nFirst, we need to import dash_bootstrap_components in our previous example.\nNext, we will add bootstrap css to your program and then we will create our layout.\nimport dash-bootstrap-components as dbc\napp = dash.Dash(__name__,external_stylesheets=[dbc.themes.BOOTSTRAP])\n\n# column1 content\ncolumn_1 = [\n    html.H2(\"\"House Prices\"\"),\n    html.P(\"\"This is a demo application which shows house prices with house area.\"\"\n    ),\n    dbc.Button(\"\"Details\"\", color=\"\"secondary\"\"),\n]\n\n# column content\ncolumn_2 = [\n    html.H2(\"\"Graph\"\"),\n    dcc.Graph(id='first',\n        figure={'data':list_of_data}),\n]\n\n# Creating layout\nbody = dbc.Container(\n    [   html.H1('With Bootstrap'),\n        html.Hr(),\n        dbc.Row(\n            [\n                dbc.Col(column_1,md=4),\n                dbc.Col(column_2,md=8),\n            ]\n        )\n    ]\n)\n\n# Adding CSS\n# dash-bootstrap-components has CDN for bootstrap css in dbc.themes.BOOTSTRAP\napp = dash.Dash(__name__,external_stylesheets=[dbc.themes.BOOTSTRAP])\nYou can chek the above source code here."
  },
  {
    "objectID": "posts/post-with-code/facial-features.html",
    "href": "posts/post-with-code/facial-features.html",
    "title": "Facial feature extraction using OpenFace",
    "section": "",
    "text": "In this post, I will discuss the work I have been doing recently. I needed to extract facial features from the recorded video and for this task, I decided to use OpenFace, an open-source face recognition library. In this post, I am sharing the installation process and tutorial on detecting facial landmarks.\n\n\nInstallation\nI tried to install OpenFace on Mac OS but couldn’t succeed. There were a lot of errors and compatibility issues that I couldn’t get through. Therefore, I decided to install it on Ubuntu. For that, I installed a Virtual box on Mac and installed Ubuntu 18.04.\nTo install OpenFace, I followed the steps given here\nsudo apt-get update\nsudo apt-get install build-essential\nsudo apt-get install g++-8\n\nsudo apt-get install cmake\n\nsudo apt-get install git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev\n\nsudo apt-get install python-dev python-numpy libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libdc1394-22-dev\n\nwget https://github.com/opencv/opencv/archive/4.1.0.zip\n\nsudo unzip 4.1.0.zip\ncd opencv-4.1.0\nmkdir build\ncd build\n\ncmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D BUILD_TIFF=ON -D WITH_TBB=ON ..\nmake -j2\nsudo make install\n\nwget http://dlib.net/files/dlib-19.13.tar.bz2\ntar xf dlib-19.13.tar.bz2\ncd dlib-19.13\nmkdir build\ncd build\ncmake ..\ncmake --build . --config Release\nsudo make install\nsudo ldconfig\ncd ../..\n\nsudo apt-get install libboost-all-dev\n\ngit clone https://github.com/TadasBaltrusaitis/OpenFace.git\n\ncd OpenFace\nmkdir build\ncd build\n\ncmake -D CMAKE_CXX_COMPILER=g++-8 -D CMAKE_C_COMPILER=gcc-8 -D CMAKE_BUILD_TYPE=RELEASE ..\nmake\nAt this point, we have installed OpenFace. Now we need to download models. You can either download it manually or use a script provided in the OpenFace library.\nManual download links.\n\nscale 0.25\nscale 0.35\nscale 0.50\nscale 1.00\n\nI ran the following command to ran the script to download the model.\ncd ..\nsh ./download_models.sh\nThe script will download models in the directory OpenFace/lib/local/LandmarkDetector/model/patch_experts.\nAfter completing this process, I ran the demo program by running the following command.\n./bin/FaceLandmarkVid -f \"\"../samples/changeLighting.wmv\"\" -f \"\"../samples/2015-10-15-15-14.avi\n\n\n\n\n\n\nExecution error\n\n\n\nI got an error CEN patch expert not found. The command was searching the models in the OpenFace/build/bin/model/patch_experts.\n\n\n\n\n\n\n\n\nSolution\n\n\n\nI copied the files (cen_patches_0.25_of.dat,cen_patches_0.35_of.dat,cen_patches_0.50_of.dat,cen_patches_1.00_of.dat) in OpenFace/build/bin/model/patch_experts directory.\n\n\n\n\nRunning Demo\nIf you have a video with a single face, you can use FaceLandmarkVid or in case of multiple faces, you can use FaceLandmarkVidMulti\n\n\n\n\n\n\nNote\n\n\n\nThese files will be available in OpenFace/build/bin directory. Either you can specify the full path to facial landmark detector or cd to the bin directory and run the following command.\n\n\nFaceLandmarkVid -f file_name\nFollowing is the demonstration of OpenFace on a video clip with single face."
  },
  {
    "objectID": "posts/concepts/pca.html",
    "href": "posts/concepts/pca.html",
    "title": "Understanding Principal Component Analysis under the hood",
    "section": "",
    "text": "Let’s assume that you have a dataset with a higher number of attributes and you are thinking Is there any way to compress this information into a smaller number of attributes. Well, dimensionality reduction methods offer that functionality. Among many dimensionality reduction methods, PCA (Principal Component Analysis) is widely used and this post introduction to PCA and its working.\nLet’s start with a simple dataset with two attributes, \\(x\\), and \\(y\\) which we need to reduce from two attributes to one. \n\n\n\n\n\n\n$x$\n$y$\n\n\n10\n5\n\n\n12\n5\n\n\n16\n6\n\n\n20\n7\n\n\n19\n5\n\n\n\n\n\n\n\n\n\nThe simplest approach is to select one of the attributes. Let’s say we are selecting \\(x\\). In other words, we are taking the projection of the data points on X-axis (Projection: simply drawing a perpendicular line from data points to the x-axis and taking that corresponding value). For example, in the following diagram, we have taken the projection of data points along the x-axis.\nSo here we have two options, we can take the projection of data points to either x-axis or y-axis. Our aim is to select one which offers more information about the data. To measure it, we can use variance which computes spread of data or in other words how the values are different from their mean value. So if you have an attribute with zero variance that means all values in that attribute are same. Variance can be computed using the following formula \\[ \\sigma^2 = \\sum\\limits_{i=1}^N (X -\\mu)^2 \\] where: \\(X\\) is the set of data points \\(\\mu\\) is the mean \\(N\\) is the number of data points in \\(X\\)\n\n\n\n\nSo, now if we look at our options (projection along x-axis or y-axis) then we find x-axis as a better option due to the larger variance shown in below figure\n\n\n\n\n\n\n\n\n\n\n\nDo we really have only these two options?\n\n\n\nNo, there are infinite number of possibilities (How: draw any line and take the projection of data points on that line in a similar manner as we did with x/y axis). In this case, if we can find a line which gives maximum variance of the data compared to other possible options then it can be used at the place of \\(x\\) and \\(y\\) attributes.\n\n\n\nPrincipal Component Analysis (PCA)\n\nAs we discussed in the above section the infinite possibilities for our two-dimensional data, PCA finds the one which offers maximum variance. Let’s go deeper into the mathematics of PCA.\n\n\n\n\nUnderstanding Mathematics behind PCA\n\n\nFirst, we are going to write the problem statement (finding a direction/vector/line which offers a maximum variance of projected data) of PCA into mathematics format. First, we need to see how to represent the projection. A projection of a data point along with a line can be computed using \\(dot\\) product. Let’s say we want to compute the projection of the first data point (10,5) on the x-axis. Let’s represent our data point as a vector \\(\\vec{x_1}\\). A vector has two properties- direction and magnitude (more info). The unit vector in the direction of x-axis and y-axis is represented by \\(\\hat{i}\\) and \\(\\hat{j}\\), respectively. Every vector then denoted by number of units in the direction of x-axis and y-axis. Our data point (10,5) can be represented as 10 units in x-axis direction and 5 units in y-axis direction. The dot product between \\(\\vec{x_1}\\) and \\(\\hat{i}\\) will give the projection over the x-axis.\n\n\n\n\n\\[= (10\\hat{i},5\\hat{j}) . (\\hat{i},0)\\]\n\n\n\n\n\\[= 10\\]\n\n\n\n\n\n\n\nIn simpler terms, if you have two vectors or list of numbers \\((a_1,a_2,a_3)\\) and\\((b_1,b_2,b_3)\\) then their dot product will be \\(a_1*b_1+a_2*b_2+a_3*b_3\\). It can be written in matrix form as following \\[\n      dot(A,B)=\\begin{bmatrix}\n      a_1 & a_2 & a_3\\\n      \\end{bmatrix}\\begin{bmatrix}\n      b_1 \\\\\n      b_2 \\\\\n      b_3 \\\\\n      \\end{bmatrix}\n     = A^TB\n  \\] here, \\(A^T\\) is transpose of \\(A\\).\n\n\n\n\n\n\n\n\nTip\n\n\n\nA dot product of \\(\\vec{A}\\) with its own gives you \\(A^2\\).\n\n\n\\[\n  A^2 = a_1^2+a_2^2+a_3^2 &lt;br/&gt;\n  = a_1*a_1+a_2*a_2+a_3*a_3\n  = A^TA\n  \\]\n\nNow coming back to PCA problem statement, let’s denote a direction (/vector/line) \\(\\vec{L}\\). So projection of our dataset \\(X\\) can be written as \\[\nX_{new}=X^TL\n\\] here, \\(X_{new}\\) represents the new values obtained after projection of \\(X\\) over \\(L\\). To ease the understanding of next step, let’s assume we transformed \\(X_{new}\\) in such a way that it has zero mean (we can do that by simply replacing every value in \\(X_{new}\\) by \\(X_{new}-Mean)\\). Next, we compute the variance of \\(X_{new}\\).\n\\[\nvar(X_{new}) = (X_{new}-0)^2 \\\\\n= X_{new}^2 \\\\\n= X_{new}^TX_{new}\n= (X^TL)^T(X^TL)\n= (L^TXX^TL)\n= (L^T  \\sum L)\n\\]\n\nhere, \\(\\sum\\) is covariance matrix of \\(X_{new}\\).\n\n\n\n\n\n\n\nTip\n\n\n\nRule used: \\((AB)^T = B^TA^T\\) and \\((A^T)^T = A\\)\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe add a constraint that L must be a unit vector which means \\(L^TL=1\\).\nWhy: In a single direction there can be infinite possibilities for example \\(2\\hat{i}+1\\hat{j}\\), \\(4\\hat{i}+2\\hat{j}\\), \\(\\hat{i}+.5\\hat{j}\\) all vectors are in the same direction. Therefore, to avoid it, we put a constraint that we will check only a single vector in a direction and that one with unit vector (to avoid large values).\n\n\nNow, our problem is to find \\(L\\) which maximizes \\(var(X_{new})\\) with constraint \\(L^TL=1\\) (constrain of unit vector). (also known as constrained maximization problem)\nTo formulate this problem, we will use Lagrange Multiplier. Our problem can be written as follows \\[\n\\max_{L} = (L^T\\sum L)-\\lambda(L^TL-1)\n\\]\n\nTo solve it, we will differentiate it with respect to \\(L\\) and then equate it to zero. As we seen above that \\(L^TL=L^2\\), therefore, differentiating it gives us \\(2L\\). \\[\n\\sum L - \\lambda (L) = 0\n\\]\n\n\n\n\n\\[ \\sum L = \\lambda L \\]\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe above equation is actually stating that \\(L\\) must be eigenvector of covariance matrix of \\(X\\).\nA brief about eigen vector\n\n\n\n\n\nLet’s consider a matrix as a system of transformation. When it is multiplied with a vector that vector gets transformed into a new vector. Let’s take an example. We have a matrix \\[ M =\n    \\begin{bmatrix}\n      2 & -4 \\\\\n      -1 &  -1 \\\\\n      \\end{bmatrix}\n  \\] We will multiply (or apply) it on a vector \\(A = [2,3]\\). The multiplication of \\(M\\) and \\(A\\) will give \\[\n  \\begin{bmatrix}\n      2 & -4 \\\\\n      -1 &  -1 \\\\\n      \\end{bmatrix}\n  \\begin{bmatrix}\n      3 \\\\\n      2  \\\\\n      \\end{bmatrix}\n  = \\begin{bmatrix}\n      -2 \\\\\n      -5 \\\\\n      \\end{bmatrix}\n  \\] As it’s shown in the below figure that point (3,2) transformed into new point (-2,-5). Now, if we multiply \\(B = [1,1]\\) with M then we will get result in the same direction. \\[\n  \\begin{bmatrix}\n      2 & -4 \\\\\n      -1 &  -1 \\\\\n      \\end{bmatrix}\n  \\begin{bmatrix}\n      1 \\\\\n      1  \\\\\n      \\end{bmatrix}\n  = \\begin{bmatrix}\n      -2 \\\\\n      -1 \\\\\n      \\end{bmatrix}\n  = -2\\begin{bmatrix}\n      1 \\\\\n      1 \\\\\n      \\end{bmatrix}\n  \\]\nTherefore vector \\(B\\) is eigen vector for the matrix in above example.\n\n\n\n\nComing back to our last equation \\(\\sum L = \\lambda L\\), now the question is which eigenvector (as there can be many eigen vectors of a matrix) to use. Let’s have a look on our variance \\((L^T\\sum L)\\) which we want to maximize.\n\n\\[\n= (L^T\\sum L)\n= (L^T\\lambda L)\n= \\lambda(L^T L)\n= \\lambda\n\\] \n\n\n\n\n\n\nTip\n\n\n\nSo, to maximize the variance, we need to take eigenvector with maximum eigen value (\\(\\lambda\\)). Here is our first vector, one with highest Eigen value.\n\n\nUsing this result as a basis, we then have the following steps for PCA\n\n\n\n\n\nCompute Covariance matrix (\\(\\sum\\)) of \\(X\\)\n\n\nSubtract \\(X_\\mu\\) (mean) from \\(X\\)\n\n\nCompute eigenvector \\(\\sum\\)\n\n\nReorder the eigen vectors according to their corresponding eigen value\n\n\nProject data set on those eigenvectors beginning from the start (as the first eigenvector has the highest eigenvalue, second eigenvector with second-highest, and so on)\n\n\n\n\n\nKey points\n\n\n\n\n\nPCA is a unsupvervised machine learning algorithm.\n\n\nPCA dimensions are linear combinations of original attributes. Therefore, it is a linear DR method. However, there are variants of PCA (e.g. kernelPCA) which offers non-linearity feature.\n\n\nUneven data range of attributes can influence the PCA results, therefore, standardize your data before applying PCA.\n\n\n\n\n\n\nExample\nPython’s library scikit-learn has numerous inbuilt functions for dimensionality reduction. In this example, we will see how to use that function. First, we need to import the packages\n\n\n\n# For loading iris dataset\nfrom sklearn import datasets\n\n# For standardizing our data\nfrom sklearn.preprocessing import StandardScaler\n\n# For PCA\nfrom sklearn import decomposition\n\n\n# Load your dataset here\niris = datasets.load_iris()\n\n# In the next step, we will standardize our data.&lt;/p&gt;\n\n# Creating Standard Scaler\nscaler = StandardScaler()\n\n# Fitting iris data to a scaler\nscaler.fit(iris)\n\n# Transform the data into standardised form\nnew_iris = scaler.transform(iris)\n\n# Create PCA object\npca = decomposition.PCA(n_components=3)\n\n# Fitting data to PCA\npca.fit(new_iris)\n\n# Computing new dimensions\ndr_iris = pca.transform(new_iris)\nLet’s check now how much variance offered by new dimensions. There is an attribute of PCA class in sklearn library: explained_variance_ratio_ which offer this information.\nprint(PCA.explained_variance_ratio_)\n# Output\n# array([0.72962445, 0.22850762, 0.03668922])&lt;/code&gt;&lt;/pre&gt;\nAs it can be seen that first two principal components offered in total around 94% variance o f original data."
  },
  {
    "objectID": "Projects.html",
    "href": "Projects.html",
    "title": "Projects",
    "section": "",
    "text": "The following projects focus on utilizing the power of analytics to support teaching and learning experience.\n\n\nDemo | Publication | Source code\nPython, Dash\n\nA Raspberry Pi-based prototype to capture audio data from face-to-face group activity\nAnalyzed the direction of arrival of captured audio to compute speaking time and turn-taking using python\nDeveloped an interactive dashboard for data visualization\n\n\n\n\n\n:trophy: Best Demo Award at Learning Analytics and Knowledge (LAK2023) conference, Texas, USA (Core A rank)\nDemo | Publication | Source code\nPython , jQuery, MySQL, Etherpad, plotly, Google Speech-to-Text\n\nPython Django app to collect multimodal learning data from group activities in classrooms\nVoice activity detection to compute speaking time of individual in group activities in real-time\nGoogle Speech-To-Text integration to process audio in real-time\nA real-time dashboard visualizing group’s writing behavior, speaking participation, and speech content (in the form of word cloud)\n\n\n\n\n\n\nPublication | Source code\nPython , Scikit-learn, Matplotlib\n\nAnalyzed audio and log data gathered from Estonian classrooms during group activities\nExplored use of different temporal window size (30s, 60s, 90s, 120s, 180s, 240s) to process features such as speaking time, turn-taking\nDeveloped machine learning models to predict collaboration quality using audio and log data features processed with different window sizes\n\n\n\n\n\n\nPublication\nPython , Scikit-learn, Matplotlib\n\nAnalyzed audio, video and log data to develop machine learning models to predict collaboration quality in classroom settings during group activity\nUsed Random Forest algorithm to develop model and evaluated its generalizability with a different dataset collected from a different Estonian school"
  },
  {
    "objectID": "Projects.html#edtech-projects",
    "href": "Projects.html#edtech-projects",
    "title": "Projects",
    "section": "",
    "text": "The following projects focus on utilizing the power of analytics to support teaching and learning experience.\n\n\nDemo | Publication | Source code\nPython, Dash\n\nA Raspberry Pi-based prototype to capture audio data from face-to-face group activity\nAnalyzed the direction of arrival of captured audio to compute speaking time and turn-taking using python\nDeveloped an interactive dashboard for data visualization\n\n\n\n\n\n:trophy: Best Demo Award at Learning Analytics and Knowledge (LAK2023) conference, Texas, USA (Core A rank)\nDemo | Publication | Source code\nPython , jQuery, MySQL, Etherpad, plotly, Google Speech-to-Text\n\nPython Django app to collect multimodal learning data from group activities in classrooms\nVoice activity detection to compute speaking time of individual in group activities in real-time\nGoogle Speech-To-Text integration to process audio in real-time\nA real-time dashboard visualizing group’s writing behavior, speaking participation, and speech content (in the form of word cloud)\n\n\n\n\n\n\nPublication | Source code\nPython , Scikit-learn, Matplotlib\n\nAnalyzed audio and log data gathered from Estonian classrooms during group activities\nExplored use of different temporal window size (30s, 60s, 90s, 120s, 180s, 240s) to process features such as speaking time, turn-taking\nDeveloped machine learning models to predict collaboration quality using audio and log data features processed with different window sizes\n\n\n\n\n\n\nPublication\nPython , Scikit-learn, Matplotlib\n\nAnalyzed audio, video and log data to develop machine learning models to predict collaboration quality in classroom settings during group activity\nUsed Random Forest algorithm to develop model and evaluated its generalizability with a different dataset collected from a different Estonian school"
  }
]